{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from spektral.data import Dataset, Graph\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(mol):\n",
    "    \n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    nodes = np.concatenate((\n",
    "        np.array([(\n",
    "            atom.GetAtomicNum(), \n",
    "            atom.GetDoubleProp(\"_GasteigerCharge\")) \n",
    "        for atom in mol.GetAtoms()]),\n",
    "        mol.GetConformer().GetPositions()[:,:2]),\n",
    "        axis=1\n",
    "    )\n",
    "    return nodes\n",
    "\n",
    "def symmetrize(matrix):\n",
    "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
    "\n",
    "def get_edges(mol):\n",
    "    \n",
    "    natms = mol.GetNumAtoms()\n",
    "    edges = np.zeros((natms, natms))\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges[i, j] = bond.GetBondTypeAsDouble()\n",
    "    \n",
    "    return symmetrize(edges)[:, :, None]\n",
    "\n",
    "def isfloat(s):\n",
    "    \n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    \n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "def get_labels(mol, key='IC50 (nM)'):\n",
    "    \"\"\"Generate label data for each molecule\n",
    "    \n",
    "    \"rank\" indicates precense or absence of angle brackets,\n",
    "    which are reported for concentrations beyond detection limits.\n",
    "    rank = 1 when \"<\", 2 when \">\", and 3 when none\n",
    "    \n",
    "    \"conc\" containts the reported concentration values\n",
    "    angle brackets are removed and boundary values are saved.\n",
    "    when conc value is 0, it means metric was not reported.\n",
    "    \n",
    "    \"\"\"\n",
    "    # read potency metric\n",
    "    sample = mol.GetPropsAsDict()[key]\n",
    "    # remove leading and trailing whitespaces\n",
    "    sample = sample.strip()\n",
    "        \n",
    "    # below exp. range\n",
    "    if \"<\" in sample: \n",
    "        \n",
    "        rank = 1\n",
    "        conc = sample.replace('<', '')\n",
    "\n",
    "    # outside exp. range\n",
    "    elif \">\" in sample:\n",
    "        \n",
    "        rank = 2\n",
    "        conc = sample.replace('>', '')\n",
    "\n",
    "    # inside exp. range\n",
    "    elif isfloat(sample):\n",
    "        \n",
    "        rank = 3\n",
    "        conc = sample\n",
    "\n",
    "    # no data provided\n",
    "    else:\n",
    "        rank = 3\n",
    "        conc = 0.0\n",
    "    \n",
    "    return np.array([rank, float(conc)])\n",
    "\n",
    "# create instance of sdf reader\n",
    "suppl = Chem.SDMolSupplier('../datasets/estrogen_receptor_alpha.sdf', sanitize=True, strictParsing=True)\n",
    "\n",
    "# read all molecules besides ones with errors into a list\n",
    "mols = [mol for mol in suppl if mol is not None]\n",
    "\n",
    "# Get nodes\n",
    "x = [get_nodes(mol) for mol in mols]\n",
    "    \n",
    "# Adjacency matrices\n",
    "a = [Chem.rdmolops.GetAdjacencyMatrix(mol) for mol in mols]\n",
    "\n",
    "# Edge features: bond types\n",
    "e = [get_edges(mol) for mol in mols]\n",
    "\n",
    "# Labels: (rank, IC50s)\n",
    "# this metric is less reliable than e.g. Kd as \n",
    "# it depends on the of the substrates used in \n",
    "# the essay and it is cell type dependent.\n",
    "y = [get_labels(mol) for mol in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "delayed-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstrogenDB(Dataset):\n",
    "    \"\"\"Dataset from BindingDB\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples, nodes, edges, adjcs, feats, dpath, **kwargs):\n",
    "        self.n_samples = n_samples\n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.adjcs = adjcs\n",
    "        self.feats = feats\n",
    "        # dataset directory\n",
    "        self.dpath = dpath\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def read(self):\n",
    "        # create Graph objects\n",
    "        data = np.load(os.path.join(\n",
    "            self.dpath, f'EstrogenDB.npz'), \n",
    "                       allow_pickle=True)\n",
    "        \n",
    "        output = [\n",
    "            self.make_graph(\n",
    "                node=data['x'][i],\n",
    "                adjc=data['a'][i], \n",
    "                edge=data['e'][i],\n",
    "                feat=data['y'][i])\n",
    "            for i in range(self.n_samples)\n",
    "            if data['y'][i][1] != 0\n",
    "        ]\n",
    "        \n",
    "        self.n_samples = len(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def download(self):\n",
    "        # save graph arrays into directory\n",
    "        filename = os.path.join(self.dpath, f'EstrogenDB')\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            filename, \n",
    "            x=self.nodes, \n",
    "            a=self.adjcs, \n",
    "            e=self.edges, \n",
    "            y=self.feats)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_graph(node, adjc, edge, feat):\n",
    "        # The node features\n",
    "        x = node.astype(float)\n",
    "        \n",
    "        # The adjacency matrix\n",
    "        # convert to scipy.sparse matrix\n",
    "        a = adjc.astype(int)\n",
    "        a = sp.csr_matrix(a)\n",
    "        # check shape (n_nodes, n_nodes)\n",
    "        assert len(node) == a.shape[0]\n",
    "        assert len(node) == a.shape[1]\n",
    "        \n",
    "        # The labels\n",
    "        y = feat.astype(float)\n",
    "        \n",
    "        # The edge features \n",
    "        e = edge.astype(float)\n",
    "        \n",
    "        return Graph(x=x, a=a, e=e, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = EstrogenDB(\n",
    "    n_samples=len(y),\n",
    "    nodes=x, edges=e, \n",
    "    adjcs=a, feats=y, \n",
    "    dpath='/Users/TiNoel/AnacondaProjects/ChemGraphs/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-iraqi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handmade-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, \n",
    "    Activation, Dropout,\n",
    "    BatchNormalization\n",
    ")\n",
    "\n",
    "from spektral.data import BatchLoader\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.layers import (\n",
    "    ECCConv, GCSConv, \n",
    "    MinCutPool, GlobalSumPool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "historical-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the adjacency matrix \n",
    "# according to ECCConv\n",
    "dataset.apply(LayerPreprocess(ECCConv))\n",
    "\n",
    "# randomize indexes\n",
    "indxs = np.random.permutation(len(dataset))\n",
    "\n",
    "# split 90%/10%\n",
    "split = int(0.9 * len(dataset))\n",
    "\n",
    "# Train/test indexes\n",
    "trnxs, tesxs = np.split(indxs, [split])\n",
    "\n",
    "# Dataset partition\n",
    "train, tests = dataset[trnxs], dataset[tesxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "activated-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # Number of training epochs\n",
    "batch_size = 32 # MiniBatch sizes\n",
    "learning_rate = 1e-3 # Optimizer learning rate\n",
    "\n",
    "n_layers = 3  # number of ECCConv layers\n",
    "n_neurons = 8  # number of Dense channels\n",
    "n_channels = [64, 32, 32]  # number of Hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decreased-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn_model(nodes_shape, edges_shape, n_channels, n_layers, n_neurons):\n",
    "    \n",
    "    X = Input(shape=(None, nodes_shape))\n",
    "    A = Input(shape=(None, None))\n",
    "    E = Input(shape=(None, None, edges_shape))\n",
    "\n",
    "    y = ECCConv(n_channels[0])([X, A, E])\n",
    "    y = Activation('relu')(y)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        y = ECCConv(n_channels[i + 1])([y, A, E])\n",
    "        y = BatchNormalization(renorm=True)(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Dropout(0.05)(y)\n",
    "    \n",
    "    # pooling graphs to 4 nodes\n",
    "    #y, Z = MinCutPool(4, mlp_hidden=[8, 16])([y, A])\n",
    "    #y = GCSConv(48)([y, Z])\n",
    "    #y = Activation('relu')(y)\n",
    "    \n",
    "    # prediction\n",
    "    y = GlobalSumPool()(y)\n",
    "    y = Dense(n_neurons)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "    O = Dense(2)(y)\n",
    "    \n",
    "    return Model(inputs=[X, A, E], outputs=O)\n",
    "\n",
    "\n",
    "def train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons): \n",
    "    \n",
    "    # Parameters\n",
    "    F = dataset.n_node_features  # Dimension of node features\n",
    "    S = dataset.n_edge_features  # Dimension of edge features\n",
    "\n",
    "    # Create GCN model\n",
    "    model = gcn_model(\n",
    "        nodes_shape=F, \n",
    "        edges_shape=S, \n",
    "        n_layers=n_layers, \n",
    "        n_neurons=n_neurons,\n",
    "        n_channels=n_channels, \n",
    "    )\n",
    "    \n",
    "    # Compile GCN\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=learning_rate), \n",
    "        metrics=[\"mae\"],\n",
    "        loss=\"mse\")\n",
    "    \n",
    "    # Print network summary\n",
    "    model.summary()\n",
    "    \n",
    "    loader = BatchLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    # Trains the model\n",
    "    history = model.fit(\n",
    "        loader.load(),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=loader.steps_per_epoch)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv (ECCConv)              (None, None, 64)     768         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 64)     0           ecc_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_1 (ECCConv)            (None, None, 32)     6144        activation[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 32)     224         ecc_conv_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_2 (ECCConv)            (None, None, 32)     3072        dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 32)     224         ecc_conv_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 32)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "min_cut_pool (MinCutPool)       [(None, 4, 32), (Non 476         dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gcs_conv (GCSConv)              (None, 4, 48)        3072        min_cut_pool[0][0]               \n",
      "                                                                 min_cut_pool[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 48)        0           gcs_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_sum_pool (GlobalSumPool) (None, 48)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            392         global_sum_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            18          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,390\n",
      "Trainable params: 14,070\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - 3489s 33s/step - loss: 9259750511.5596 - mae: 8983.2032\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 3621s 34s/step - loss: 11808719778.5688 - mae: 9477.4405\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 3565s 33s/step - loss: 8297444868.6972 - mae: 10170.8878\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 3378s 32s/step - loss: 13971569499.5963 - mae: 12993.8677\n",
      "Epoch 5/20\n",
      " 42/108 [==========>...................] - ETA: 52:44 - loss: 27348222420.7619 - mae: 17369.0178"
     ]
    }
   ],
   "source": [
    "model, history = train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model\")\n",
    "loader = BatchLoader(tests, batch_size=batch_size)\n",
    "model_loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
    "print(\"Done. Test loss: {}\".format(model_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-islam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
