{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alejogiley/ChemGraphs/blob/prototype/notebooks/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPwXmOxKK0Su",
    "outputId": "fd59b81c-c3be-42c3-812f-6d57ab681813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 34.6M  100 34.6M    0     0   194M      0 --:--:-- --:--:-- --:--:--  194M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "url='https://raw.githubusercontent.com/alejogiley/ChemGraphs/prototype/datasets/estrogen_receptor_alpha.sdf'\n",
    "curl $url --output estrogen_receptor_alpha.sdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm2ocr1791OM",
    "outputId": "cbba3ed3-b05f-496e-82f7-9eef0c848782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  3681    0  3681    0     0  36810      0 --:--:-- --:--:-- --:--:-- 37181\n",
      "\r",
      "  3 20.2M    3  628k    0     0  1544k      0  0:00:13 --:--:--  0:00:13 1544k\r",
      " 42 20.2M   42 8889k    0     0  6247k      0  0:00:03  0:00:01  0:00:02 8138k\r",
      " 75 20.2M   75 15.2M    0     0  6501k      0  0:00:03  0:00:02  0:00:01 7513k\r",
      "100 20.2M  100 20.2M    0     0  6712k      0  0:00:03  0:00:03 --:--:-- 7500k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "x86='/usr/lib/x86_64-linux-gnu'\n",
    "url='https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
    "\n",
    "# download & extract\n",
    "curl -L $url | tar xj lib\n",
    "\n",
    "# move to python packages directory\n",
    "mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.6/dist-packages/\n",
    "mv lib/*.so.* $x86/\n",
    "\n",
    "# rdkit need libboost\n",
    "ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r8yo69a-_5lN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lz_dCAvc_yEA"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DpNOLnf-nvtU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, \n",
    "    Activation, Dropout,\n",
    "    BatchNormalization)\n",
    "\n",
    "from spektral.data import BatchLoader, Dataset, Graph\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.layers import (\n",
    "    ECCConv, GCSConv, \n",
    "    MinCutPool, GlobalSumPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "D-w2A1TMnvtd"
   },
   "outputs": [],
   "source": [
    "def get_nodes(mol):\n",
    "    \n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    nodes = np.concatenate((\n",
    "        np.array([(\n",
    "            atom.GetAtomicNum(), \n",
    "            atom.GetDoubleProp(\"_GasteigerCharge\")) \n",
    "        for atom in mol.GetAtoms()]),\n",
    "        mol.GetConformer().GetPositions()[:,:2]),\n",
    "        axis=1\n",
    "    )\n",
    "    return nodes\n",
    "\n",
    "def symmetrize(matrix):\n",
    "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
    "\n",
    "def get_edges(mol):\n",
    "    \n",
    "    natms = mol.GetNumAtoms()\n",
    "    edges = np.zeros((natms, natms))\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges[i, j] = bond.GetBondTypeAsDouble()\n",
    "    \n",
    "    return symmetrize(edges)[:, :, None]\n",
    "\n",
    "def isfloat(s):\n",
    "    \n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    \n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "def get_labels(mol, key='IC50 (nM)'):\n",
    "    \"\"\"Generate label data for each molecule\n",
    "    \n",
    "    \"rank\" indicates precense or absence of angle brackets,\n",
    "    which are reported for concentrations beyond detection limits.\n",
    "    rank = 0 when \"<\", 1 when \">\", and 2 when none\n",
    "    \n",
    "    \"conc\" containts the reported concentration values\n",
    "    angle brackets are removed and boundary values are saved.\n",
    "    when conc value is 0, it means metric was not reported.\n",
    "    \n",
    "    \"\"\"\n",
    "    # read potency metric\n",
    "    sample = mol.GetPropsAsDict()[key]\n",
    "    # remove leading and trailing whitespaces\n",
    "    sample = sample.strip()\n",
    "        \n",
    "    # below exp. range\n",
    "    if \"<\" in sample: \n",
    "        \n",
    "        rank = 0\n",
    "        conc = sample.replace('<', '')\n",
    "\n",
    "    # outside exp. range\n",
    "    elif \">\" in sample:\n",
    "        \n",
    "        rank = 1\n",
    "        conc = sample.replace('>', '')\n",
    "\n",
    "    # inside exp. range\n",
    "    elif isfloat(sample):\n",
    "        \n",
    "        rank = 2\n",
    "        conc = sample\n",
    "\n",
    "    # no data provided\n",
    "    else:\n",
    "        rank = 2\n",
    "        conc = 0.0\n",
    "    \n",
    "    return np.array([rank, np.log10(float(conc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TZYsl4ELOn0d"
   },
   "outputs": [],
   "source": [
    "# create instance of sdf reader\n",
    "suppl = Chem.SDMolSupplier('estrogen_receptor_alpha.sdf', sanitize=True, strictParsing=True)\n",
    "\n",
    "# read all molecules besides ones with errors into a list\n",
    "mols = [mol for mol in suppl if mol is not None]\n",
    "\n",
    "# Get nodes\n",
    "x = [get_nodes(mol) for mol in mols]\n",
    "    \n",
    "# Adjacency matrices\n",
    "a = [Chem.rdmolops.GetAdjacencyMatrix(mol) for mol in mols]\n",
    "\n",
    "# Edge features: bond types\n",
    "e = [get_edges(mol) for mol in mols]\n",
    "\n",
    "# Labels: (rank, IC50s)\n",
    "# this metric is less reliable than e.g. Kd as \n",
    "# it depends on the of the substrates used in \n",
    "# the essay and it is cell type dependent.\n",
    "y = [get_labels(mol) for mol in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "6uXBHJI7nvtf"
   },
   "outputs": [],
   "source": [
    "class EstrogenDB(Dataset):\n",
    "    \"\"\"Dataset from BindingDB\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_samples,\n",
    "                 dpath=None, \n",
    "                 nodes=None, \n",
    "                 edges=None, \n",
    "                 adjcs=None, \n",
    "                 feats=None,\n",
    "                 **kwargs):\n",
    "        self.n_samples = n_samples\n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.adjcs = adjcs\n",
    "        self.feats = feats\n",
    "        # dataset to load\n",
    "        self.dpath = dpath\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    @Dataset.path.getter\n",
    "    def path(self):\n",
    "        return self.dpath\n",
    "        \n",
    "    def read(self):\n",
    "        # create Graph objects\n",
    "        data = np.load(os.path.join(\n",
    "            self.dpath, f'EstrogenDB.npz'), \n",
    "                       allow_pickle=True)\n",
    "        \n",
    "        output = [\n",
    "            self.make_graph(\n",
    "                node=data['x'][i],\n",
    "                adjc=data['a'][i], \n",
    "                edge=data['e'][i],\n",
    "                feat=data['y'][i])\n",
    "            for i in range(self.n_samples)\n",
    "            if data['y'][i][1] != 0\n",
    "        ]\n",
    "        \n",
    "        self.n_samples = len(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def download(self):\n",
    "        # save graph arrays into directory\n",
    "        filename = os.path.join(self.dpath, f'EstrogenDB')\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            filename, \n",
    "            x=self.nodes, \n",
    "            a=self.adjcs, \n",
    "            e=self.edges, \n",
    "            y=self.feats)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_graph(node, adjc, edge, feat):\n",
    "        # The node features\n",
    "        x = node.astype(float)\n",
    "        \n",
    "        # The adjacency matrix\n",
    "        # convert to scipy.sparse matrix\n",
    "        a = adjc.astype(int)\n",
    "        a = sp.csr_matrix(a)\n",
    "        # check shape (n_nodes, n_nodes)\n",
    "        assert a.shape[0] == len(node)\n",
    "        assert a.shape[1] == len(node)\n",
    "        \n",
    "        # The labels\n",
    "        y = feat.astype(float)\n",
    "        # transform IC50 values\n",
    "        # into pIC50 logscaled\n",
    "        y[1] = np.log10(y[1])\n",
    "        \n",
    "        # The edge features \n",
    "        e = edge.astype(float)\n",
    "        # check shape (n_nodes, n_nodes, ..)\n",
    "        assert e.shape[0] == len(node)\n",
    "        assert e.shape[1] == len(node)\n",
    "        \n",
    "        return Graph(x=x, a=a, e=e, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhDKKqITnvtf",
    "outputId": "c4bb3642-56d4-49d8-d7a1-de7abca9677b"
   },
   "outputs": [],
   "source": [
    "url = \"../datasets\"\n",
    "\n",
    "# dataset = EstrogenDB(\n",
    "#     n_samples=1000,\n",
    "#     nodes=x, edges=e, \n",
    "#     adjcs=a, feats=y, \n",
    "#     dpath=url)\n",
    "\n",
    "dataset = EstrogenDB(n_samples=1000, dpath=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "_SYHcgUtnvth"
   },
   "outputs": [],
   "source": [
    "# Transform the adjacency matrix \n",
    "# according to ECCConv\n",
    "dataset.apply(LayerPreprocess(ECCConv))\n",
    "\n",
    "# randomize indexes\n",
    "indxs = np.random.permutation(len(dataset))\n",
    "\n",
    "# split 90%/10%\n",
    "split = int(0.9 * len(dataset))\n",
    "\n",
    "# Train/test indexes\n",
    "trnxs, tesxs = np.split(indxs, [split])\n",
    "\n",
    "# Dataset partition\n",
    "train, tests = dataset[trnxs], dataset[tesxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "u-7wElUznvti"
   },
   "outputs": [],
   "source": [
    "epochs = 4  # Number of training epochs\n",
    "batch_size = 6 # MiniBatch sizes\n",
    "learning_rate = 1e-4 # Optimizer learning rate\n",
    "\n",
    "n_layers = 3  # number of ECCConv layers\n",
    "n_neurons = 8  # number of Dense channels\n",
    "n_channels = [64, 32, 32]  # number of Hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "s4duo2Minvtj"
   },
   "outputs": [],
   "source": [
    "def gcn_model(nodes_shape, edges_shape, n_channels, n_layers, n_neurons):\n",
    "    \n",
    "    X = Input(shape=(None, nodes_shape))\n",
    "    A = Input(shape=(None, None))\n",
    "    E = Input(shape=(None, None, edges_shape))\n",
    "\n",
    "    y = ECCConv(n_channels[0])([X, A, E])\n",
    "    y = Activation('relu')(y)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        y = ECCConv(n_channels[i + 1])([y, A, E])\n",
    "        y = BatchNormalization(renorm=True)(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Dropout(0.05)(y)\n",
    "    \n",
    "    # pooling graphs to 4 nodes\n",
    "    y, Z = MinCutPool(4, mlp_hidden=[8, 16])([y, A])\n",
    "    y = GCSConv(48)([y, Z])\n",
    "    y = Activation('relu')(y)\n",
    "    \n",
    "    # pooling\n",
    "    y = GlobalSumPool()(y)\n",
    "    y = Dense(n_neurons)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "    \n",
    "    # prediction\n",
    "    O = Dense(4)(y)\n",
    "    \n",
    "    return Model(inputs=[X, A, E], outputs=O)\n",
    "\n",
    "\n",
    "def msent_loss(y_true, y_pred):\n",
    "    \n",
    "    c_true, c_pred = y_true[:, 0], y_pred[:, 1:]\n",
    "    p_true, p_pred = y_true[:, 1], y_pred[:, :1]\n",
    "    \n",
    "    # categorical cross-entropy for classes: 0, 1, 2\n",
    "    ent = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  \n",
    "    # regression error for pIC50 values\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # return the overal error\n",
    "    return tf.reduce_mean(\n",
    "        ent(c_true, c_pred) + mse(p_true, p_pred))\n",
    "\n",
    "\n",
    "def train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons): \n",
    "    \n",
    "    # Parameters\n",
    "    F = dataset.n_node_features  # Dimension of node features\n",
    "    S = dataset.n_edge_features  # Dimension of edge features\n",
    "\n",
    "    # Create GCN model\n",
    "    model = gcn_model(\n",
    "        nodes_shape=F, \n",
    "        edges_shape=S, \n",
    "        n_layers=n_layers, \n",
    "        n_neurons=n_neurons,\n",
    "        n_channels=n_channels)\n",
    "    \n",
    "    # Compile GCN\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=learning_rate), \n",
    "        #metrics=[\"mae\"],\n",
    "        loss=msent_loss)\n",
    "    \n",
    "    # Print network summary\n",
    "    model.summary()\n",
    "    \n",
    "    loader = BatchLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    # Trains the model\n",
    "    history = model.fit(\n",
    "        loader.load(),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=loader.steps_per_epoch)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4aHUtt_nvtj",
    "outputId": "af793a91-b372-4618-e34b-5809f9cc41c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_78 (ECCConv)           (None, None, 64)     768         input_79[0][0]                   \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, 64)     0           ecc_conv_78[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_79 (ECCConv)           (None, None, 32)     6144        activation_113[0][0]             \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, 32)     224         ecc_conv_79[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, 32)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, None, 32)     0           activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_80 (ECCConv)           (None, None, 32)     3072        dropout_78[0][0]                 \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, 32)     224         ecc_conv_80[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, 32)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, None, 32)     0           activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "min_cut_pool_9 (MinCutPool)     [(None, 4, 32), (Non 476         dropout_79[0][0]                 \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gcs_conv_9 (GCSConv)            (None, 4, 48)        3072        min_cut_pool_9[0][0]             \n",
      "                                                                 min_cut_pool_9[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 48)        0           gcs_conv_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_sum_pool_26 (GlobalSumPo (None, 48)           0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 8)            392         global_sum_pool_26[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8)            0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8)            0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 4)            36          dropout_80[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 14,408\n",
      "Trainable params: 14,088\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      "6/6 [==============================] - 6s 355ms/step - loss: 3393.9039\n",
      "Epoch 2/4\n",
      "6/6 [==============================] - 2s 355ms/step - loss: 278.6806\n",
      "Epoch 3/4\n",
      "6/6 [==============================] - 2s 354ms/step - loss: 91.5832\n",
      "Epoch 4/4\n",
      "6/6 [==============================] - 2s 365ms/step - loss: 13.3604\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myZnKO-ynvtk",
    "outputId": "01b021c2-1b81-4a96-a74d-1ff2cabb8c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model\n",
      "WARNING:tensorflow:8 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x156d92620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.7720\n",
      "Done. Test loss: 0.7720264792442322\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model\")\n",
    "loader = BatchLoader(tests, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
    "print(\"Done. Test loss: {}\".format(model_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1597edea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "prediction = model.predict(loader.load(), steps=loader.steps_per_epoch)\n",
    "\n",
    "pIC50_true = [tests[i]['y'][1] for i in range(tests.n_graphs)]\n",
    "class_true = [tests[i]['y'][0] for i in range(tests.n_graphs)] \n",
    "\n",
    "pIC50_pred = prediction[:, :1]\n",
    "class_pred = np.argmax(np.apply_along_axis(softmax, 0, prediction[:, 1:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.8239087409443188,\n",
       "  -0.6989700043360187,\n",
       "  -0.8600013417252057,\n",
       "  -0.6989700043360187],\n",
       " array([[-0.68673813],\n",
       "        [-1.5253204 ],\n",
       "        [-1.2745371 ],\n",
       "        [-1.7179643 ]], dtype=float32))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pIC50_true, pIC50_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.0, 2.0, 2.0, 2.0], array([1, 0, 1, 2]))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_true, class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
