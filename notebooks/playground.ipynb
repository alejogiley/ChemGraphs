{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "playground.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejogiley/ChemGraphs/blob/prototype/notebooks/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm2ocr1791OM",
        "outputId": "e2857694-9d68-4bc2-fb6b-0e06d94a6621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "x86='/usr/lib/x86_64-linux-gnu'\n",
        "url='https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
        "\n",
        "# download & extract\n",
        "curl -L $url | tar xj lib\n",
        "\n",
        "# move to python packages directory\n",
        "mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.6/dist-packages/\n",
        "mv lib/*.so.* $x86/\n",
        "\n",
        "# rdkit need libboost\n",
        "ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3681    0  3681    0     0  32008      0 --:--:-- --:--:-- --:--:-- 32008\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 37 20.2M   37 7835k    0     0  7008k      0  0:00:02  0:00:01  0:00:01 7835k\r 69 20.2M   69 14.0M    0     0  6789k      0  0:00:03  0:00:02  0:00:01 7190k\r100 20.2M  100 20.2M    0     0  6970k      0  0:00:02  0:00:02 --:--:-- 7263k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8yo69a-_5lN"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz_dCAvc_yEA",
        "outputId": "bf379023-15cc-4ed1-da95-a868f4798791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spektral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/74/9834dc2270f19316f7a394e32525bab93a4e244760a320d5f16c82111315/spektral-1.0.4-py3-none-any.whl (116kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 32.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 40kB 21.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 61kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 71kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 81kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 92kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 102kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 112kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from spektral) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spektral) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spektral) (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from spektral) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spektral) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from spektral) (0.22.2.post1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->spektral) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2020.12.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->spektral) (51.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpNOLnf-nvtU"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Input, \n",
        "    Activation, Dropout,\n",
        "    BatchNormalization)\n",
        "\n",
        "from spektral.data import BatchLoader, Dataset, Graph\n",
        "from spektral.transforms import LayerPreprocess\n",
        "from spektral.layers import (\n",
        "    ECCConv, GCSConv, \n",
        "    MinCutPool, GlobalSumPool)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-w2A1TMnvtd"
      },
      "source": [
        "def get_nodes(mol):\n",
        "    \n",
        "    AllChem.ComputeGasteigerCharges(mol)\n",
        "    nodes = np.concatenate((\n",
        "        np.array([(\n",
        "            atom.GetAtomicNum(), \n",
        "            atom.GetDoubleProp(\"_GasteigerCharge\")) \n",
        "        for atom in mol.GetAtoms()]),\n",
        "        mol.GetConformer().GetPositions()[:,:2]),\n",
        "        axis=1\n",
        "    )\n",
        "    return nodes\n",
        "\n",
        "def symmetrize(matrix):\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "def get_edges(mol):\n",
        "    \n",
        "    natms = mol.GetNumAtoms()\n",
        "    edges = np.zeros((natms, natms))\n",
        "    \n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        edges[i, j] = bond.GetBondTypeAsDouble()\n",
        "    \n",
        "    return symmetrize(edges)[:, :, None]\n",
        "\n",
        "def isfloat(s):\n",
        "    \n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    \n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    \n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        " \n",
        "    return False\n",
        "\n",
        "def get_labels(mol, key='IC50 (nM)'):\n",
        "    \"\"\"Generate label data for each molecule\n",
        "    \n",
        "    \"rank\" indicates precense or absence of angle brackets,\n",
        "    which are reported for concentrations beyond detection limits.\n",
        "    rank = 1 when \"<\", 2 when \">\", and 3 when none\n",
        "    \n",
        "    \"conc\" containts the reported concentration values\n",
        "    angle brackets are removed and boundary values are saved.\n",
        "    when conc value is 0, it means metric was not reported.\n",
        "    \n",
        "    \"\"\"\n",
        "    # read potency metric\n",
        "    sample = mol.GetPropsAsDict()[key]\n",
        "    # remove leading and trailing whitespaces\n",
        "    sample = sample.strip()\n",
        "        \n",
        "    # below exp. range\n",
        "    if \"<\" in sample: \n",
        "        \n",
        "        rank = 1\n",
        "        conc = sample.replace('<', '')\n",
        "\n",
        "    # outside exp. range\n",
        "    elif \">\" in sample:\n",
        "        \n",
        "        rank = 2\n",
        "        conc = sample.replace('>', '')\n",
        "\n",
        "    # inside exp. range\n",
        "    elif isfloat(sample):\n",
        "        \n",
        "        rank = 3\n",
        "        conc = sample\n",
        "\n",
        "    # no data provided\n",
        "    else:\n",
        "        rank = 3\n",
        "        conc = 0.0\n",
        "    \n",
        "    return np.array([rank, float(conc)])\n",
        "\n",
        "# create instance of sdf reader\n",
        "suppl = Chem.SDMolSupplier('../datasets/estrogen_receptor_alpha.sdf', sanitize=True, strictParsing=True)\n",
        "\n",
        "# read all molecules besides ones with errors into a list\n",
        "mols = [mol for mol in suppl if mol is not None]\n",
        "\n",
        "# Get nodes\n",
        "x = [get_nodes(mol) for mol in mols]\n",
        "    \n",
        "# Adjacency matrices\n",
        "a = [Chem.rdmolops.GetAdjacencyMatrix(mol) for mol in mols]\n",
        "\n",
        "# Edge features: bond types\n",
        "e = [get_edges(mol) for mol in mols]\n",
        "\n",
        "# Labels: (rank, IC50s)\n",
        "# this metric is less reliable than e.g. Kd as \n",
        "# it depends on the of the substrates used in \n",
        "# the essay and it is cell type dependent.\n",
        "y = [get_labels(mol) for mol in mols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce88DnQjnvte"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uXBHJI7nvtf"
      },
      "source": [
        "class EstrogenDB(Dataset):\n",
        "    \"\"\"Dataset from BindingDB\n",
        "    \"\"\"\n",
        "    def __init__(self, n_samples, nodes, edges, adjcs, feats, dpath, **kwargs):\n",
        "        self.n_samples = n_samples\n",
        "        self.nodes = nodes\n",
        "        self.edges = edges\n",
        "        self.adjcs = adjcs\n",
        "        self.feats = feats\n",
        "        # dataset directory\n",
        "        self.dpath = dpath\n",
        "        \n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def read(self):\n",
        "        # create Graph objects\n",
        "        data = np.load(os.path.join(\n",
        "            self.dpath, f'EstrogenDB.npz'), \n",
        "                       allow_pickle=True)\n",
        "        \n",
        "        output = [\n",
        "            self.make_graph(\n",
        "                node=data['x'][i],\n",
        "                adjc=data['a'][i], \n",
        "                edge=data['e'][i],\n",
        "                feat=data['y'][i])\n",
        "            for i in range(self.n_samples)\n",
        "            if data['y'][i][1] != 0\n",
        "        ]\n",
        "        \n",
        "        self.n_samples = len(output)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def download(self):\n",
        "        # save graph arrays into directory\n",
        "        filename = os.path.join(self.dpath, f'EstrogenDB')\n",
        "        \n",
        "        np.savez_compressed(\n",
        "            filename, \n",
        "            x=self.nodes, \n",
        "            a=self.adjcs, \n",
        "            e=self.edges, \n",
        "            y=self.feats)\n",
        "    \n",
        "    @staticmethod\n",
        "    def make_graph(node, adjc, edge, feat):\n",
        "        # The node features\n",
        "        x = node.astype(float)\n",
        "        \n",
        "        # The adjacency matrix\n",
        "        # convert to scipy.sparse matrix\n",
        "        a = adjc.astype(int)\n",
        "        a = sp.csr_matrix(a)\n",
        "        # check shape (n_nodes, n_nodes)\n",
        "        assert len(node) == a.shape[0]\n",
        "        assert len(node) == a.shape[1]\n",
        "        \n",
        "        # The labels\n",
        "        y = feat.astype(float)\n",
        "        \n",
        "        # The edge features \n",
        "        e = edge.astype(float)\n",
        "        \n",
        "        return Graph(x=x, a=a, e=e, y=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDKKqITnvtf",
        "outputId": "c897decf-add8-4ce5-a2e9-09a3c7d0bc02"
      },
      "source": [
        "dataset = EstrogenDB(\n",
        "    n_samples=len(y),\n",
        "    nodes=x, edges=e, \n",
        "    adjcs=a, feats=y, \n",
        "    dpath='../datasets')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_t1bmdcnvth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SYHcgUtnvth"
      },
      "source": [
        "# Transform the adjacency matrix \n",
        "# according to ECCConv\n",
        "dataset.apply(LayerPreprocess(ECCConv))\n",
        "\n",
        "# randomize indexes\n",
        "indxs = np.random.permutation(len(dataset))\n",
        "\n",
        "# split 90%/10%\n",
        "split = int(0.9 * len(dataset))\n",
        "\n",
        "# Train/test indexes\n",
        "trnxs, tesxs = np.split(indxs, [split])\n",
        "\n",
        "# Dataset partition\n",
        "train, tests = dataset[trnxs], dataset[tesxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-7wElUznvti"
      },
      "source": [
        "epochs = 20  # Number of training epochs\n",
        "batch_size = 32 # MiniBatch sizes\n",
        "learning_rate = 1e-3 # Optimizer learning rate\n",
        "\n",
        "n_layers = 3  # number of ECCConv layers\n",
        "n_neurons = 8  # number of Dense channels\n",
        "n_channels = [64, 32, 32]  # number of Hidden units"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4duo2Minvtj"
      },
      "source": [
        "def gcn_model(nodes_shape, edges_shape, n_channels, n_layers, n_neurons):\n",
        "    \n",
        "    X = Input(shape=(None, nodes_shape))\n",
        "    A = Input(shape=(None, None))\n",
        "    E = Input(shape=(None, None, edges_shape))\n",
        "\n",
        "    y = ECCConv(n_channels[0])([X, A, E])\n",
        "    y = Activation('relu')(y)\n",
        "    \n",
        "    for i in range(n_layers - 1):\n",
        "        y = ECCConv(n_channels[i + 1])([y, A, E])\n",
        "        y = BatchNormalization(renorm=True)(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Dropout(0.05)(y)\n",
        "    \n",
        "    # pooling graphs to 4 nodes\n",
        "    #y, Z = MinCutPool(4, mlp_hidden=[8, 16])([y, A])\n",
        "    #y = GCSConv(48)([y, Z])\n",
        "    #y = Activation('relu')(y)\n",
        "    \n",
        "    # prediction\n",
        "    y = GlobalSumPool()(y)\n",
        "    y = Dense(n_neurons)(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "    O = Dense(2)(y)\n",
        "    \n",
        "    return Model(inputs=[X, A, E], outputs=O)\n",
        "\n",
        "\n",
        "def train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons): \n",
        "    \n",
        "    # Parameters\n",
        "    F = dataset.n_node_features  # Dimension of node features\n",
        "    S = dataset.n_edge_features  # Dimension of edge features\n",
        "\n",
        "    # Create GCN model\n",
        "    model = gcn_model(\n",
        "        nodes_shape=F, \n",
        "        edges_shape=S, \n",
        "        n_layers=n_layers, \n",
        "        n_neurons=n_neurons,\n",
        "        n_channels=n_channels, \n",
        "    )\n",
        "    \n",
        "    # Compile GCN\n",
        "    model.compile(\n",
        "        optimizer=Adam(lr=learning_rate), \n",
        "        metrics=[\"mae\"],\n",
        "        loss=\"mse\")\n",
        "    \n",
        "    # Print network summary\n",
        "    model.summary()\n",
        "    \n",
        "    loader = BatchLoader(\n",
        "        dataset, \n",
        "        batch_size=batch_size)\n",
        "    \n",
        "    # Trains the model\n",
        "    history = model.fit(\n",
        "        loader.load(),\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=loader.steps_per_epoch)\n",
        "    \n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4aHUtt_nvtj",
        "outputId": "6bc43273-ee32-4fb0-bc42-848ff1387356"
      },
      "source": [
        "model, history = train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, None)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv (ECCConv)              (None, None, 64)     768         input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, None, 64)     0           ecc_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_1 (ECCConv)            (None, None, 32)     6144        activation[0][0]                 \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, 32)     224         ecc_conv_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, 32)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 32)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_2 (ECCConv)            (None, None, 32)     3072        dropout[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, 32)     224         ecc_conv_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, 32)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 32)     0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "min_cut_pool (MinCutPool)       [(None, 4, 32), (Non 476         dropout_1[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gcs_conv (GCSConv)              (None, 4, 48)        3072        min_cut_pool[0][0]               \n",
            "                                                                 min_cut_pool[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4, 48)        0           gcs_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_sum_pool (GlobalSumPool) (None, 48)           0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 8)            392         global_sum_pool[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8)            0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8)            0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            18          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,390\n",
            "Trainable params: 14,070\n",
            "Non-trainable params: 320\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "108/108 [==============================] - 3489s 33s/step - loss: 9259750511.5596 - mae: 8983.2032\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 3621s 34s/step - loss: 11808719778.5688 - mae: 9477.4405\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 3565s 33s/step - loss: 8297444868.6972 - mae: 10170.8878\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 3378s 32s/step - loss: 13971569499.5963 - mae: 12993.8677\n",
            "Epoch 5/20\n",
            " 42/108 [==========>...................] - ETA: 52:44 - loss: 27348222420.7619 - mae: 17369.0178"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZnKO-ynvtk"
      },
      "source": [
        "print(\"Testing model\")\n",
        "loader = BatchLoader(tests, batch_size=batch_size)\n",
        "model_loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
        "print(\"Done. Test loss: {}\".format(model_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaOMaazUnvtk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}