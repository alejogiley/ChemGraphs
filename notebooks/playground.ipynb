{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alejogiley/ChemGraphs/blob/prototype/notebooks/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPwXmOxKK0Su",
    "outputId": "fd59b81c-c3be-42c3-812f-6d57ab681813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 34.6M  100 34.6M    0     0   194M      0 --:--:-- --:--:-- --:--:--  194M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "url='https://raw.githubusercontent.com/alejogiley/ChemGraphs/prototype/datasets/estrogen_receptor_alpha.sdf'\n",
    "curl $url --output estrogen_receptor_alpha.sdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm2ocr1791OM",
    "outputId": "cbba3ed3-b05f-496e-82f7-9eef0c848782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  3681    0  3681    0     0  36810      0 --:--:-- --:--:-- --:--:-- 37181\n",
      "\r",
      "  3 20.2M    3  628k    0     0  1544k      0  0:00:13 --:--:--  0:00:13 1544k\r",
      " 42 20.2M   42 8889k    0     0  6247k      0  0:00:03  0:00:01  0:00:02 8138k\r",
      " 75 20.2M   75 15.2M    0     0  6501k      0  0:00:03  0:00:02  0:00:01 7513k\r",
      "100 20.2M  100 20.2M    0     0  6712k      0  0:00:03  0:00:03 --:--:-- 7500k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "x86='/usr/lib/x86_64-linux-gnu'\n",
    "url='https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
    "\n",
    "# download & extract\n",
    "curl -L $url | tar xj lib\n",
    "\n",
    "# move to python packages directory\n",
    "mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.6/dist-packages/\n",
    "mv lib/*.so.* $x86/\n",
    "\n",
    "# rdkit need libboost\n",
    "ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r8yo69a-_5lN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lz_dCAvc_yEA"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DpNOLnf-nvtU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, \n",
    "    Activation, Dropout,\n",
    "    BatchNormalization)\n",
    "\n",
    "from spektral.data import BatchLoader, Dataset, Graph\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.layers import (\n",
    "    ECCConv, GCSConv, \n",
    "    MinCutPool, GlobalSumPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D-w2A1TMnvtd"
   },
   "outputs": [],
   "source": [
    "def get_nodes(mol):\n",
    "    \n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    nodes = np.concatenate((\n",
    "        np.array([(\n",
    "            atom.GetAtomicNum(), \n",
    "            atom.GetDoubleProp(\"_GasteigerCharge\")) \n",
    "        for atom in mol.GetAtoms()]),\n",
    "        mol.GetConformer().GetPositions()[:,:2]),\n",
    "        axis=1\n",
    "    )\n",
    "    return nodes\n",
    "\n",
    "def symmetrize(matrix):\n",
    "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
    "\n",
    "def get_edges(mol):\n",
    "    \n",
    "    natms = mol.GetNumAtoms()\n",
    "    edges = np.zeros((natms, natms))\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges[i, j] = bond.GetBondTypeAsDouble()\n",
    "    \n",
    "    return symmetrize(edges)[:, :, None]\n",
    "\n",
    "def isfloat(s):\n",
    "    \n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    \n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "def get_labels(mol, key='IC50 (nM)'):\n",
    "    \"\"\"Generate label data for each molecule\n",
    "    \n",
    "    \"rank\" indicates precense or absence of angle brackets,\n",
    "    which are reported for concentrations beyond detection limits.\n",
    "    rank = 1 when \"<\", 2 when \">\", and 3 when none\n",
    "    \n",
    "    \"conc\" containts the reported concentration values\n",
    "    angle brackets are removed and boundary values are saved.\n",
    "    when conc value is 0, it means metric was not reported.\n",
    "    \n",
    "    \"\"\"\n",
    "    # read potency metric\n",
    "    sample = mol.GetPropsAsDict()[key]\n",
    "    # remove leading and trailing whitespaces\n",
    "    sample = sample.strip()\n",
    "        \n",
    "    # below exp. range\n",
    "    if \"<\" in sample: \n",
    "        \n",
    "        rank = 1\n",
    "        conc = sample.replace('<', '')\n",
    "\n",
    "    # outside exp. range\n",
    "    elif \">\" in sample:\n",
    "        \n",
    "        rank = 2\n",
    "        conc = sample.replace('>', '')\n",
    "\n",
    "    # inside exp. range\n",
    "    elif isfloat(sample):\n",
    "        \n",
    "        rank = 3\n",
    "        conc = sample\n",
    "\n",
    "    # no data provided\n",
    "    else:\n",
    "        rank = 3\n",
    "        conc = 0.0\n",
    "    \n",
    "    return np.array([rank, float(conc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TZYsl4ELOn0d"
   },
   "outputs": [],
   "source": [
    "# create instance of sdf reader\n",
    "suppl = Chem.SDMolSupplier('estrogen_receptor_alpha.sdf', sanitize=True, strictParsing=True)\n",
    "\n",
    "# read all molecules besides ones with errors into a list\n",
    "mols = [mol for mol in suppl if mol is not None]\n",
    "\n",
    "# Get nodes\n",
    "x = [get_nodes(mol) for mol in mols]\n",
    "    \n",
    "# Adjacency matrices\n",
    "a = [Chem.rdmolops.GetAdjacencyMatrix(mol) for mol in mols]\n",
    "\n",
    "# Edge features: bond types\n",
    "e = [get_edges(mol) for mol in mols]\n",
    "\n",
    "# Labels: (rank, IC50s)\n",
    "# this metric is less reliable than e.g. Kd as \n",
    "# it depends on the of the substrates used in \n",
    "# the essay and it is cell type dependent.\n",
    "y = [get_labels(mol) for mol in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6uXBHJI7nvtf"
   },
   "outputs": [],
   "source": [
    "class EstrogenDB(Dataset):\n",
    "    \"\"\"Dataset from BindingDB\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_samples,\n",
    "                 dpath=None, \n",
    "                 nodes=None, \n",
    "                 edges=None, \n",
    "                 adjcs=None, \n",
    "                 feats=None,\n",
    "                 **kwargs):\n",
    "        self.n_samples = n_samples\n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.adjcs = adjcs\n",
    "        self.feats = feats\n",
    "        # dataset to load\n",
    "        self.dpath = dpath\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    @Dataset.path.getter\n",
    "    def path(self):\n",
    "        return self.dpath\n",
    "        \n",
    "    def read(self):\n",
    "        # create Graph objects\n",
    "        data = np.load(os.path.join(\n",
    "            self.dpath, f'EstrogenDB.npz'), \n",
    "                       allow_pickle=True)\n",
    "        \n",
    "        output = [\n",
    "            self.make_graph(\n",
    "                node=data['x'][i],\n",
    "                adjc=data['a'][i], \n",
    "                edge=data['e'][i],\n",
    "                feat=data['y'][i])\n",
    "            for i in range(self.n_samples)\n",
    "            if data['y'][i][1] != 0\n",
    "        ]\n",
    "        \n",
    "        self.n_samples = len(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def download(self):\n",
    "        # save graph arrays into directory\n",
    "        filename = os.path.join(self.dpath, f'EstrogenDB')\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            filename, \n",
    "            x=self.nodes, \n",
    "            a=self.adjcs, \n",
    "            e=self.edges, \n",
    "            y=self.feats)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_graph(node, adjc, edge, feat):\n",
    "        # The node features\n",
    "        x = node.astype(float)\n",
    "        \n",
    "        # The adjacency matrix\n",
    "        # convert to scipy.sparse matrix\n",
    "        a = adjc.astype(int)\n",
    "        a = sp.csr_matrix(a)\n",
    "        # check shape (n_nodes, n_nodes)\n",
    "        assert a.shape[0] == len(node)\n",
    "        assert a.shape[1] == len(node)\n",
    "        \n",
    "        # The labels\n",
    "        y = feat.astype(float)\n",
    "        \n",
    "        # The edge features \n",
    "        e = edge.astype(float)\n",
    "        # check shape (n_nodes, n_nodes, ..)\n",
    "        assert e.shape[0] == len(node)\n",
    "        assert e.shape[1] == len(node)\n",
    "        \n",
    "        return Graph(x=x, a=a, e=e, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhDKKqITnvtf",
    "outputId": "c4bb3642-56d4-49d8-d7a1-de7abca9677b"
   },
   "outputs": [],
   "source": [
    "url = \"../datasets\"\n",
    "\n",
    "# dataset = EstrogenDB(\n",
    "#     n_samples=1000,\n",
    "#     nodes=x, edges=e, \n",
    "#     adjcs=a, feats=y, \n",
    "#     dpath=url)\n",
    "\n",
    "dataset = EstrogenDB(n_samples=1000, dpath=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_SYHcgUtnvth"
   },
   "outputs": [],
   "source": [
    "# Transform the adjacency matrix \n",
    "# according to ECCConv\n",
    "dataset.apply(LayerPreprocess(ECCConv))\n",
    "\n",
    "# randomize indexes\n",
    "indxs = np.random.permutation(len(dataset))\n",
    "\n",
    "# split 90%/10%\n",
    "split = int(0.9 * len(dataset))\n",
    "\n",
    "# Train/test indexes\n",
    "trnxs, tesxs = np.split(indxs, [split])\n",
    "\n",
    "# Dataset partition\n",
    "train, tests = dataset[trnxs], dataset[tesxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "u-7wElUznvti"
   },
   "outputs": [],
   "source": [
    "epochs = 4  # Number of training epochs\n",
    "batch_size = 6 # MiniBatch sizes\n",
    "learning_rate = 1e-3 # Optimizer learning rate\n",
    "\n",
    "n_layers = 3  # number of ECCConv layers\n",
    "n_neurons = 8  # number of Dense channels\n",
    "n_channels = [64, 32, 32]  # number of Hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s4duo2Minvtj"
   },
   "outputs": [],
   "source": [
    "def gcn_model(nodes_shape, edges_shape, n_channels, n_layers, n_neurons):\n",
    "    \n",
    "    X = Input(shape=(None, nodes_shape))\n",
    "    A = Input(shape=(None, None))\n",
    "    E = Input(shape=(None, None, edges_shape))\n",
    "\n",
    "    y = ECCConv(n_channels[0])([X, A, E])\n",
    "    y = Activation('relu')(y)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        y = ECCConv(n_channels[i + 1])([y, A, E])\n",
    "        y = BatchNormalization(renorm=True)(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Dropout(0.05)(y)\n",
    "    \n",
    "    # pooling graphs to 4 nodes\n",
    "    # y, Z = MinCutPool(4, mlp_hidden=[8, 16])([y, A])\n",
    "    # y = GCSConv(48)([y, Z])\n",
    "    # y = Activation('relu')(y)\n",
    "    \n",
    "    # prediction\n",
    "    y = GlobalSumPool()(y)\n",
    "    y = Dense(n_neurons)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "    O = Dense(2)(y)\n",
    "    \n",
    "    return Model(inputs=[X, A, E], outputs=O)\n",
    "\n",
    "\n",
    "def train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons): \n",
    "    \n",
    "    # Parameters\n",
    "    F = dataset.n_node_features  # Dimension of node features\n",
    "    S = dataset.n_edge_features  # Dimension of edge features\n",
    "\n",
    "    # Create GCN model\n",
    "    model = gcn_model(\n",
    "        nodes_shape=F, \n",
    "        edges_shape=S, \n",
    "        n_layers=n_layers, \n",
    "        n_neurons=n_neurons,\n",
    "        n_channels=n_channels)\n",
    "    \n",
    "    # Compile GCN\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=learning_rate), \n",
    "        metrics=[\"mae\"],\n",
    "        loss=\"mse\")\n",
    "    \n",
    "    # Print network summary\n",
    "    model.summary()\n",
    "    \n",
    "    loader = BatchLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    # Trains the model\n",
    "    history = model.fit(\n",
    "        loader.load(),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=loader.steps_per_epoch)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4aHUtt_nvtj",
    "outputId": "af793a91-b372-4618-e34b-5809f9cc41c7"
   },
   "outputs": [],
   "source": [
    "model, history = train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myZnKO-ynvtk",
    "outputId": "01b021c2-1b81-4a96-a74d-1ff2cabb8c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 4.5642 - mae: 1.5620\n",
      "Done. Test loss: [4.564227104187012, 1.562017560005188]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model\")\n",
    "loader = BatchLoader(tests, batch_size=batch_size)\n",
    "model_loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
    "print(\"Done. Test loss: {}\".format(model_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
