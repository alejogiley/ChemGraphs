{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "playground.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejogiley/ChemGraphs/blob/prototype/notebooks/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPwXmOxKK0Su",
        "outputId": "fd59b81c-c3be-42c3-812f-6d57ab681813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "url='https://raw.githubusercontent.com/alejogiley/ChemGraphs/prototype/datasets/estrogen_receptor_alpha.sdf'\n",
        "curl $url --output estrogen_receptor_alpha.sdf "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 34.6M  100 34.6M    0     0   194M      0 --:--:-- --:--:-- --:--:--  194M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm2ocr1791OM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbba3ed3-b05f-496e-82f7-9eef0c848782"
      },
      "source": [
        "%%bash\n",
        "\n",
        "x86='/usr/lib/x86_64-linux-gnu'\n",
        "url='https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
        "\n",
        "# download & extract\n",
        "curl -L $url | tar xj lib\n",
        "\n",
        "# move to python packages directory\n",
        "mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.6/dist-packages/\n",
        "mv lib/*.so.* $x86/\n",
        "\n",
        "# rdkit need libboost\n",
        "ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3681    0  3681    0     0  36810      0 --:--:-- --:--:-- --:--:-- 37181\n",
            "\r  3 20.2M    3  628k    0     0  1544k      0  0:00:13 --:--:--  0:00:13 1544k\r 42 20.2M   42 8889k    0     0  6247k      0  0:00:03  0:00:01  0:00:02 8138k\r 75 20.2M   75 15.2M    0     0  6501k      0  0:00:03  0:00:02  0:00:01 7513k\r100 20.2M  100 20.2M    0     0  6712k      0  0:00:03  0:00:03 --:--:-- 7500k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8yo69a-_5lN"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz_dCAvc_yEA"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install spektral"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpNOLnf-nvtU"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Input, \n",
        "    Activation, Dropout,\n",
        "    BatchNormalization)\n",
        "\n",
        "from spektral.data import BatchLoader, Dataset, Graph\n",
        "from spektral.transforms import LayerPreprocess\n",
        "from spektral.layers import (\n",
        "    ECCConv, GCSConv, \n",
        "    MinCutPool, GlobalSumPool)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-w2A1TMnvtd"
      },
      "source": [
        "def get_nodes(mol):\n",
        "    \n",
        "    AllChem.ComputeGasteigerCharges(mol)\n",
        "    nodes = np.concatenate((\n",
        "        np.array([(\n",
        "            atom.GetAtomicNum(), \n",
        "            atom.GetDoubleProp(\"_GasteigerCharge\")) \n",
        "        for atom in mol.GetAtoms()]),\n",
        "        mol.GetConformer().GetPositions()[:,:2]),\n",
        "        axis=1\n",
        "    )\n",
        "    return nodes\n",
        "\n",
        "def symmetrize(matrix):\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "def get_edges(mol):\n",
        "    \n",
        "    natms = mol.GetNumAtoms()\n",
        "    edges = np.zeros((natms, natms))\n",
        "    \n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        edges[i, j] = bond.GetBondTypeAsDouble()\n",
        "    \n",
        "    return symmetrize(edges)[:, :, None]\n",
        "\n",
        "def isfloat(s):\n",
        "    \n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    \n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    \n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        " \n",
        "    return False\n",
        "\n",
        "def get_labels(mol, key='IC50 (nM)'):\n",
        "    \"\"\"Generate label data for each molecule\n",
        "    \n",
        "    \"rank\" indicates precense or absence of angle brackets,\n",
        "    which are reported for concentrations beyond detection limits.\n",
        "    rank = 1 when \"<\", 2 when \">\", and 3 when none\n",
        "    \n",
        "    \"conc\" containts the reported concentration values\n",
        "    angle brackets are removed and boundary values are saved.\n",
        "    when conc value is 0, it means metric was not reported.\n",
        "    \n",
        "    \"\"\"\n",
        "    # read potency metric\n",
        "    sample = mol.GetPropsAsDict()[key]\n",
        "    # remove leading and trailing whitespaces\n",
        "    sample = sample.strip()\n",
        "        \n",
        "    # below exp. range\n",
        "    if \"<\" in sample: \n",
        "        \n",
        "        rank = 1\n",
        "        conc = sample.replace('<', '')\n",
        "\n",
        "    # outside exp. range\n",
        "    elif \">\" in sample:\n",
        "        \n",
        "        rank = 2\n",
        "        conc = sample.replace('>', '')\n",
        "\n",
        "    # inside exp. range\n",
        "    elif isfloat(sample):\n",
        "        \n",
        "        rank = 3\n",
        "        conc = sample\n",
        "\n",
        "    # no data provided\n",
        "    else:\n",
        "        rank = 3\n",
        "        conc = 0.0\n",
        "    \n",
        "    return np.array([rank, float(conc)])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZYsl4ELOn0d"
      },
      "source": [
        "# create instance of sdf reader\n",
        "suppl = Chem.SDMolSupplier('estrogen_receptor_alpha.sdf', sanitize=True, strictParsing=True)\n",
        "\n",
        "# read all molecules besides ones with errors into a list\n",
        "mols = [mol for mol in suppl if mol is not None]\n",
        "\n",
        "# Get nodes\n",
        "x = [get_nodes(mol) for mol in mols]\n",
        "    \n",
        "# Adjacency matrices\n",
        "a = [Chem.rdmolops.GetAdjacencyMatrix(mol) for mol in mols]\n",
        "\n",
        "# Edge features: bond types\n",
        "e = [get_edges(mol) for mol in mols]\n",
        "\n",
        "# Labels: (rank, IC50s)\n",
        "# this metric is less reliable than e.g. Kd as \n",
        "# it depends on the of the substrates used in \n",
        "# the essay and it is cell type dependent.\n",
        "y = [get_labels(mol) for mol in mols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uXBHJI7nvtf"
      },
      "source": [
        "class EstrogenDB(Dataset):\n",
        "    \"\"\"Dataset from BindingDB\n",
        "    \"\"\"\n",
        "    def __init__(self, n_samples, nodes, edges, adjcs, feats, dpath, **kwargs):\n",
        "        self.n_samples = n_samples\n",
        "        self.nodes = nodes\n",
        "        self.edges = edges\n",
        "        self.adjcs = adjcs\n",
        "        self.feats = feats\n",
        "        # dataset directory\n",
        "        self.dpath = dpath\n",
        "        \n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def read(self):\n",
        "        # create Graph objects\n",
        "        data = np.load(os.path.join(\n",
        "            self.dpath, f'EstrogenDB.npz'), \n",
        "                       allow_pickle=True)\n",
        "        \n",
        "        output = [\n",
        "            self.make_graph(\n",
        "                node=data['x'][i],\n",
        "                adjc=data['a'][i], \n",
        "                edge=data['e'][i],\n",
        "                feat=data['y'][i])\n",
        "            for i in range(self.n_samples)\n",
        "            if data['y'][i][1] != 0\n",
        "        ]\n",
        "        \n",
        "        self.n_samples = len(output)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def download(self):\n",
        "        # save graph arrays into directory\n",
        "        filename = os.path.join(self.dpath, f'EstrogenDB')\n",
        "        \n",
        "        np.savez_compressed(\n",
        "            filename, \n",
        "            x=self.nodes, \n",
        "            a=self.adjcs, \n",
        "            e=self.edges, \n",
        "            y=self.feats)\n",
        "    \n",
        "    @staticmethod\n",
        "    def make_graph(node, adjc, edge, feat):\n",
        "        # The node features\n",
        "        x = node.astype(float)\n",
        "        \n",
        "        # The adjacency matrix\n",
        "        # convert to scipy.sparse matrix\n",
        "        a = adjc.astype(int)\n",
        "        a = sp.csr_matrix(a)\n",
        "        # check shape (n_nodes, n_nodes)\n",
        "        assert a.shape[0] == len(node)\n",
        "        assert a.shape[1] == len(node)\n",
        "        \n",
        "        # The labels\n",
        "        y = feat.astype(float)\n",
        "        \n",
        "        # The edge features \n",
        "        e = edge.astype(float)\n",
        "        # check shape (n_nodes, n_nodes, ..)\n",
        "        assert e.shape[0] == len(node)\n",
        "        assert e.shape[1] == len(node)\n",
        "        \n",
        "        return Graph(x=x, a=a, e=e, y=y)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDKKqITnvtf",
        "outputId": "c4bb3642-56d4-49d8-d7a1-de7abca9677b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = EstrogenDB(\n",
        "    n_samples=1000,\n",
        "    nodes=x, edges=e, \n",
        "    adjcs=a, feats=y, \n",
        "    dpath='/content/sample_data')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SYHcgUtnvth"
      },
      "source": [
        "# Transform the adjacency matrix \n",
        "# according to ECCConv\n",
        "dataset.apply(LayerPreprocess(ECCConv))\n",
        "\n",
        "# randomize indexes\n",
        "indxs = np.random.permutation(len(dataset))\n",
        "\n",
        "# split 90%/10%\n",
        "split = int(0.9 * len(dataset))\n",
        "\n",
        "# Train/test indexes\n",
        "trnxs, tesxs = np.split(indxs, [split])\n",
        "\n",
        "# Dataset partition\n",
        "train, tests = dataset[trnxs], dataset[tesxs]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-7wElUznvti"
      },
      "source": [
        "epochs = 40  # Number of training epochs\n",
        "batch_size = 32 # MiniBatch sizes\n",
        "learning_rate = 1e-3 # Optimizer learning rate\n",
        "\n",
        "n_layers = 3  # number of ECCConv layers\n",
        "n_neurons = 8  # number of Dense channels\n",
        "n_channels = [64, 32, 32]  # number of Hidden units"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4duo2Minvtj"
      },
      "source": [
        "def gcn_model(nodes_shape, edges_shape, n_channels, n_layers, n_neurons):\n",
        "    \n",
        "    X = Input(shape=(None, nodes_shape))\n",
        "    A = Input(shape=(None, None))\n",
        "    E = Input(shape=(None, None, edges_shape))\n",
        "\n",
        "    y = ECCConv(n_channels[0])([X, A, E])\n",
        "    y = Activation('relu')(y)\n",
        "    \n",
        "    for i in range(n_layers - 1):\n",
        "        y = ECCConv(n_channels[i + 1])([y, A, E])\n",
        "        y = BatchNormalization(renorm=True)(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Dropout(0.05)(y)\n",
        "    \n",
        "    # pooling graphs to 4 nodes\n",
        "    y, Z = MinCutPool(4, mlp_hidden=[8, 16])([y, A])\n",
        "    y = GCSConv(48)([y, Z])\n",
        "    y = Activation('relu')(y)\n",
        "    \n",
        "    # prediction\n",
        "    y = GlobalSumPool()(y)\n",
        "    y = Dense(n_neurons)(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "    O = Dense(2)(y)\n",
        "    \n",
        "    return Model(inputs=[X, A, E], outputs=O)\n",
        "\n",
        "\n",
        "def train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons): \n",
        "    \n",
        "    # Parameters\n",
        "    F = dataset.n_node_features  # Dimension of node features\n",
        "    S = dataset.n_edge_features  # Dimension of edge features\n",
        "\n",
        "    # Create GCN model\n",
        "    model = gcn_model(\n",
        "        nodes_shape=F, \n",
        "        edges_shape=S, \n",
        "        n_layers=n_layers, \n",
        "        n_neurons=n_neurons,\n",
        "        n_channels=n_channels, \n",
        "    )\n",
        "    \n",
        "    # Compile GCN\n",
        "    model.compile(\n",
        "        optimizer=Adam(lr=learning_rate), \n",
        "        metrics=[\"mae\"],\n",
        "        loss=\"mse\")\n",
        "    \n",
        "    # Print network summary\n",
        "    model.summary()\n",
        "    \n",
        "    loader = BatchLoader(\n",
        "        dataset, \n",
        "        batch_size=batch_size)\n",
        "    \n",
        "    # Trains the model\n",
        "    history = model.fit(\n",
        "        loader.load(),\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=loader.steps_per_epoch)\n",
        "    \n",
        "    return model, history"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4aHUtt_nvtj",
        "outputId": "af793a91-b372-4618-e34b-5809f9cc41c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model, history = train_model(dataset, epochs, learning_rate, n_channels, n_layers, n_neurons)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, None, None)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_12 (ECCConv)           (None, None, 64)     768         input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, 64)     0           ecc_conv_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_13 (ECCConv)           (None, None, 32)     6144        activation_17[0][0]              \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, 32)     224         ecc_conv_13[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, 32)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, None, 32)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_14 (ECCConv)           (None, None, 32)     3072        dropout_12[0][0]                 \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, 32)     224         ecc_conv_14[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, 32)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, None, 32)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "min_cut_pool_1 (MinCutPool)     [(None, 4, 32), (Non 476         dropout_13[0][0]                 \n",
            "                                                                 input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gcs_conv_1 (GCSConv)            (None, 4, 48)        3072        min_cut_pool_1[0][0]             \n",
            "                                                                 min_cut_pool_1[0][1]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 48)        0           gcs_conv_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_sum_pool_4 (GlobalSumPoo (None, 48)           0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 8)            392         global_sum_pool_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8)            0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 8)            0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            18          dropout_14[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 14,390\n",
            "Trainable params: 14,070\n",
            "Non-trainable params: 320\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "2/2 [==============================] - 2s 17ms/step - loss: 14727.5602 - mae: 79.8720\n",
            "Epoch 2/40\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 4612.0654 - mae: 50.5171\n",
            "Epoch 3/40\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 527.5432 - mae: 14.0869\n",
            "Epoch 4/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 714.1932 - mae: 17.2209\n",
            "Epoch 5/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 686.4265 - mae: 18.2955\n",
            "Epoch 6/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 277.9756 - mae: 11.8068\n",
            "Epoch 7/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 138.1121 - mae: 9.3439\n",
            "Epoch 8/40\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 73.6956 - mae: 6.5446\n",
            "Epoch 9/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 51.9904 - mae: 5.2412\n",
            "Epoch 10/40\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 23.0706 - mae: 3.1272\n",
            "Epoch 11/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 23.7346 - mae: 3.5222\n",
            "Epoch 12/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 25.4148 - mae: 3.6883\n",
            "Epoch 13/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 19.2246 - mae: 3.4452\n",
            "Epoch 14/40\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 16.6359 - mae: 3.1235\n",
            "Epoch 15/40\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 8.3095 - mae: 2.1897\n",
            "Epoch 16/40\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 13.7761 - mae: 2.7369\n",
            "Epoch 17/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.2954 - mae: 1.9441\n",
            "Epoch 18/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.9842 - mae: 1.8973\n",
            "Epoch 19/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.6476 - mae: 2.4423\n",
            "Epoch 20/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.4836 - mae: 2.0205\n",
            "Epoch 21/40\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.4576 - mae: 1.9993\n",
            "Epoch 22/40\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.9777 - mae: 2.0077\n",
            "Epoch 23/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.5110 - mae: 2.0495\n",
            "Epoch 24/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 4.5176 - mae: 1.6541\n",
            "Epoch 25/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.2972 - mae: 2.5040\n",
            "Epoch 26/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.9043 - mae: 2.2333\n",
            "Epoch 27/40\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.7825 - mae: 2.5819\n",
            "Epoch 28/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.3994 - mae: 2.5772\n",
            "Epoch 29/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.1505 - mae: 2.4017\n",
            "Epoch 30/40\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.9261 - mae: 2.2855\n",
            "Epoch 31/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 7.7433 - mae: 2.2060\n",
            "Epoch 32/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.5085 - mae: 2.1454\n",
            "Epoch 33/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8.6918 - mae: 2.4254\n",
            "Epoch 34/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.4854 - mae: 2.2819\n",
            "Epoch 35/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.6651 - mae: 2.6594\n",
            "Epoch 36/40\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.4144 - mae: 2.2362\n",
            "Epoch 37/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.4214 - mae: 2.4638\n",
            "Epoch 38/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.2637 - mae: 2.3347\n",
            "Epoch 39/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.8223 - mae: 1.9996\n",
            "Epoch 40/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.4187 - mae: 2.3759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZnKO-ynvtk",
        "outputId": "01b021c2-1b81-4a96-a74d-1ff2cabb8c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Testing model\")\n",
        "loader = BatchLoader(tests, batch_size=batch_size)\n",
        "model_loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
        "print(\"Done. Test loss: {}\".format(model_loss))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing model\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 4.5642 - mae: 1.5620\n",
            "Done. Test loss: [4.564227104187012, 1.562017560005188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaOMaazUnvtk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}